{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc752b2-e35c-4352-b0d1-83f9d9aeea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download pt_core_news_sm\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install pipreqs\n",
    "!export PYTHONWARNINGS=\"ignore\"\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53125385-2d68-4a3c-a179-920d95ba5e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.3\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468b0ee-800b-43b9-92f7-116cea45c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf083f-10d0-44fc-ad4b-c829fa662835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchSimilar(phrase, Comments) -> list:\n",
    "\tfilterdData = []\n",
    "\t\n",
    "\tnlp = spacy.load(\"pt_core_news_sm\")\n",
    "\tcorpus_old = phrase.split() + (list(Comments['content'].values)) #concatena a phrase na base dados\n",
    "\t\n",
    "\tfor i in corpus_old:\n",
    "\t\tfilterdData.append(clearPhrase(i, nlp, ['PROPN', 'NOUN', 'VERB'])) #eu faço uma limpeza nos comentários, deixando apenas Pronomes pessoais, adjetivos, substantivos e verbos \n",
    "\t\t\n",
    "\tprocessedData = TfidfVectorizer().fit_transform(filterdData) #transformo a base de dados em vetores de números TF-IDF\n",
    "\t\n",
    "\t[lenght, M] = processedData.shape #pego o tamanho da base de dados    \n",
    "\tsimilaritiesList = []    \n",
    "\tfor i in range(1, lenght):\n",
    "\t\ts = cosine_similarity(processedData[0],processedData[i]) #o comentário processedData[0] é a frase digitada pelo usuário, daí preciso computar a distancia dessa frase com todos os comentários da base de dados\n",
    "\t\tif(s != 0): #se a similaridade é zero, nem adiciono o comentário na lista, pois significa que ele é 0 similar\n",
    "\t\t\tsimilaritiesList.append([s, corpus_old[i]])\n",
    "\t\t\n",
    "\treturn similaritiesList   #retorna uma lista com o comentário e a distancia dele da frase que o usuário digitou\n",
    "\t\n",
    "def clearPhrase(doc, nlp, pos_tag):\n",
    "\tif(type(doc) != spacy.tokens.doc.Doc):\n",
    "\t\tdoc = nlp(doc)\n",
    "\treturn ' '.join([str(t.lemma_) for t in doc if t.pos_ in pos_tag]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d890fec7-2a42-4daf-a246-f00257158217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addHours(minDate:str,maxDate:str)-> (str,str):\n",
    "\tminDate = minDate + \"00:00:00\"\n",
    "\tmaxDate = maxDate + \"23:59:59\"\n",
    "\n",
    "\treturn minDate,maxDate\n",
    "def getComments(originPath:str,minDate:str = None,maxDate:str = None,versions = None) -> pandas.DataFrame:\n",
    "\t\n",
    "\tcommentsFile = pandas.read_csv(originPath)\n",
    "\n",
    "\tif minDate != None and maxDate != None:\n",
    "\t\tminDate,maxDate = addHours(minDate,maxDate)\n",
    "\n",
    "\tfor i in range(0, len(commentsFile)):\n",
    "\t\tif commentsFile['date'][i] < minDate or commentsFile['date'][i] > maxDate or commentsFile['version'][i] not in versions:\n",
    "\t\t\t#print(\"droped\",commentsFile['version'][i])\n",
    "\t\t\tcommentsFile = commentsFile.drop([i])\n",
    "\treturn commentsFile\n",
    "\n",
    "def sortbyThumbs(file:pandas.DataFrame) -> pandas.DataFrame:\n",
    "\tfile = file.sort_values(by=['thumbs'])\n",
    "\treturn file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be588572-69b5-4a22-a525-7e39bf4d4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = getComments(\"./General_Data.csv\",\"2021-09-01\",\"2021-10-01\",\"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e499f10-cab3-4fe3-88f6-d96a01721181",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_list = searchSimilar('recuperar senha', database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d665ec-b4ac-434d-82a7-ea2ae6edf934",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(similarities_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece906a-c137-4f9c-bc9e-4b0e2ae97a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipreqs ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121b145-1130-4e78-9397-98e81ad6c40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
